# -*- coding: utf-8 -*-
"""bert_base_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CuxSuUJxczxd6XjaEBei4dq6fsu0Z4l_
"""

pip install transformers torch scikit-learn

from transformers import pipeline, BertTokenizer, BertModel
from sklearn.metrics.pairwise import cosine_similarity
import torch

# 1. Fill-mask pipeline
unmasker = pipeline("fill-mask", model="bert-base-uncased")
print("1️⃣ Fill-Mask:")
print(unmasker("BERT is a [MASK] model."), "\n")

# 2. Text Classification (Sentiment Analysis)
classifier = pipeline("sentiment-analysis", model="nlptown/bert-base-multilingual-uncased-sentiment")  # sentiment-specific
print("2️⃣ Sentiment Analysis:")
print(classifier("I really love this product!"), "\n")

# 3. Question Answering
qa = pipeline("question-answering", model="bert-large-uncased-whole-word-masking-finetuned-squad")
context = "BERT is a model developed by Google for natural language processing tasks."
question = "Who developed BERT?"
print("3️⃣ Question Answering:")
print(qa(question=question, context=context), "\n")

# 4. Named Entity Recognition (NER)
ner = pipeline("ner", grouped_entities=True, model="dslim/bert-base-NER")
print("4️⃣ Named Entity Recognition:")
print(ner("Elon Musk founded SpaceX and lives in the United States."), "\n")

# 5. Sentence Similarity using embeddings
tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")
model = BertModel.from_pretrained("bert-base-uncased")

def get_embedding(sentence):
    tokens = tokenizer(sentence, return_tensors='pt', padding=True, truncation=True)
    with torch.no_grad():
        outputs = model(**tokens).last_hidden_state.mean(dim=1)
    return outputs

sentence1 = "I love machine learning"
sentence2 = "I like studying AI"
emb1 = get_embedding(sentence1)
emb2 = get_embedding(sentence2)
similarity = cosine_similarity(emb1, emb2)[0][0]

print("5️⃣ Sentence Similarity:")
print(f"Similarity between sentences: {similarity:.2f}")