# -*- coding: utf-8 -*-
"""ques_and_ans.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Vg2Wz6tGf3PwwkfuNpmWWoCIGULHXYnX
"""

from transformers import pipeline

# Load model and tokenizer using pipeline
model_name = "deepset/roberta-base-squad2"
qa_pipeline = pipeline("question-answering", model=model_name, tokenizer=model_name)

# Input question and context
question = "Why is model conversion important?"
context = (
    "The option to convert models between FARM and transformers gives freedom to the user "
    "and lets people easily switch between frameworks."
)

# Create input for the model
qa_input = {
    "question": question,
    "context": context
}

# Get the answer
result = qa_pipeline(qa_input)

# Print the answer
print("Question:", question)
print("Answer:", result['answer'])
print("Score:", result['score'])